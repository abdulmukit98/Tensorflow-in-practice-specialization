{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional Neural Networks in TensorFlow.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO64r95kPG+zJ1AQDnMra3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulmukit98/Tensorflow-in-practice-specialization/blob/master/Convolutional_Neural_Networks_in_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw81NIsWNhIw",
        "colab_type": "text"
      },
      "source": [
        "# Exploring a larger datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9geFOg-t7f49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "  -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KrYGhFgOCmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7BdIkRGPm3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir='/tmp/cats_and_dogs_filtered/train'\n",
        "validation_dir = '/tmp/cats_and_dogs_filtered/validation'\n",
        "train_cats_dir='/tmp/cats_and_dogs_filtered/train/cats'\n",
        "train_dogs_dir='/tmp/cats_and_dogs_filtered/train/dogs'\n",
        "validation_cats_dir='/tmp/cats_and_dogs_filtered/validation/cats'\n",
        "validation_dogs_dir='/tmp/cats_and_dogs_filtered/validation/dogs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWNzXX1ORcoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "print(train_cat_fnames[:10])\n",
        "print(train_dog_fnames[:10])\n",
        "\n",
        "print('total train cat images: ',len(train_cat_fnames))\n",
        "print('total train dog images: ',len(train_dog_fnames))\n",
        "\n",
        "print('total validation cat images: ', len(os.listdir(validation_cats_dir)))\n",
        "print('total validation dog images: ', len(os.listdir(validation_dogs_dir)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BW81etgX_2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7-TC4zJYmn5",
        "colab_type": "text"
      },
      "source": [
        "Display a batch of 8 cat and 8 dogs picture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_SGNfHGYtWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=8\n",
        "\n",
        "next_cat_pix = [os.path.join(train_cats_dir, i)\n",
        "      for i in train_cat_fnames[pic_index-8:pic_index]]\n",
        "\n",
        "next_dog_pix = [os.path.join(train_dogs_dir, i)\n",
        "      for i in train_dog_fnames[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_cat_pix + next_dog_pix):\n",
        "  sp = plt.subplot(nrows, ncols, i+1)\n",
        "  sp.axis('Off')\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6lTVsFkdChg",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoYtKYnjdFUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "model = tf.keras.models.Sequential([\n",
        "    tfl.Conv2D(16,(3,3),activation='relu',\n",
        "              input_shape=(150,150,3)),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.Conv2D(32,(3,3),activation='relu'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.Conv2D(64,(3,3),activation='relu'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.Flatten(),\n",
        "    tfl.Dense(512,activation='relu'),\n",
        "    tfl.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(optimizer=RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['acc'])\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255 )\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255 )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary',\n",
        "    target_size = (150,150)\n",
        ")\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    batch_size=20,\n",
        "    class_mode = 'binary',\n",
        "    target_size = (150,150)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRPGCDQekSiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data= validation_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 15,\n",
        "    validation_steps = 50,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5u-AOzTmxIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path,\n",
        "                       target_size = (150,150))\n",
        "  \n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0] > 0:\n",
        "    print(fn+\" is a dog\")\n",
        "  else:\n",
        "    print(fn+\" is a cat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LX4Cj680mCF",
        "colab_type": "text"
      },
      "source": [
        "###Evaluating accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EfOKAdr0xEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_no = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_no, acc)\n",
        "plt.plot(epochs_no, val_acc)\n",
        "plt.title('Train and validation accuracy')\n",
        "\n",
        "plt.figure() #new fig\n",
        "\n",
        "plt.plot(epochs_no, loss)\n",
        "plt.plot(epochs_no, val_loss)\n",
        "plt.title('Train and validation loss')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsm_8ALD7Dv0",
        "colab_type": "text"
      },
      "source": [
        "# Augmentation\n",
        "\n",
        "### cats versus dog with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_qB9w6QBwM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ImNFZLOCP6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "\n",
        "import tensorflow.keras.layers as tfl\n",
        "model = tf.keras.models.Sequential([\n",
        "  tfl.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)),\n",
        "  tfl.MaxPooling2D(2,2),\n",
        "  tfl.Conv2D(64, (3,3), activation='relu'),\n",
        "  tfl.MaxPooling2D(2,2),\n",
        "  tfl.Conv2D(128,(3,3),activation='relu'),\n",
        "  tfl.MaxPooling2D(2,2),\n",
        "  tfl.Conv2D(128,(3,3),activation='relu'),\n",
        "  tfl.MaxPooling2D(2,2),\n",
        "  tfl.Dropout(0.5),\n",
        "  tfl.Flatten(),\n",
        "  tfl.Dense(512, activation='relu'),\n",
        "  tfl.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = RMSprop(lr=1e-4),\n",
        "              metrics = ['acc'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ") \n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs = 100,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 50,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gg5Tb2dxkBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'g', label = 'validation acc')\n",
        "plt.legend() # make label show\n",
        "plt.title('Training and validation acc')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'g', label= 'val loss')\n",
        "plt.legend()\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpyf167-rSTT",
        "colab_type": "text"
      },
      "source": [
        "# Horse and Human with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcamBMvmrYaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
        "    -O /tmp/horse-or-human.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n",
        "    -O /tmp/validation-horse-or-human.zip\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Souxgey3rhaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/horse-or-human')\n",
        "\n",
        "local_zip = '/tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation-horse-or-human')\n",
        "zip_ref.close()\n",
        "\n",
        "train_horse_dir = '/tmp/horse-or-human/horses' \n",
        "train_human_dir = '/tmp/horse-or-human/humans'\n",
        "validation_horse_dir = '/tmp/validation-horse-or-human/horses'\n",
        "validation_human_dir = '/tmp/validation-horse-or-human/humans'\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "model = tf.keras.models.Sequential([\n",
        "        tfl.Conv2D(16,(3,3),activation='relu',\n",
        "                  input_shape=(300,300,3)),\n",
        "        tfl.MaxPooling2D(2,2),\n",
        "        tfl.Conv2D(32,(3,3),activation='relu'),\n",
        "        tfl.MaxPooling2D(2,2),\n",
        "        tfl.Conv2D(64,(3,3),activation='relu'),\n",
        "        tfl.MaxPooling2D(2,2),\n",
        "        tfl.Conv2D(64,(3,3),activation='relu'),\n",
        "        tfl.MaxPooling2D(2,2),\n",
        "        tfl.Conv2D(64,(3,3),activation='relu'),\n",
        "        tfl.MaxPooling2D(2,2),\n",
        "        tfl.Flatten(),\n",
        "        tfl.Dense(512,activation='relu'),\n",
        "        tfl.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = RMSprop(lr = 1e-4),\n",
        "              metrics=['acc']\n",
        ")\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/tmp/horse-or-human/',\n",
        "    target_size = (300,300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    '/tmp/validation-horse-or-human/',\n",
        "      target_size = (300,300),\n",
        "      batch_size = 32,\n",
        "      class_mode = 'binary'\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv3LuS-eVA7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8,\n",
        "    epochs = 20,\n",
        "    verbose = 1,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 8\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSA6PRg2Vxn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='val_acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBss9wYEavfc",
        "colab_type": "text"
      },
      "source": [
        "#Transfer Learning\n",
        "Inception datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPHvJQNmIOTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhU2wHs2IYXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(\n",
        "                        input_shape = (150,150,3),\n",
        "                        include_top = False,\n",
        "                        weights = None\n",
        ")\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for i in pre_trained_model.layers:\n",
        "  i.trainable = False\n",
        "\n",
        "pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed10')\n",
        "print('last layer output shape', last_layer.output_shape)\n",
        "\n",
        "#load all pre trained into (last_output)\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = tfl.Flatten()(last_output)\n",
        "x = tfl.Dense(1024,activation='relu')(x)\n",
        "x = tfl.Dropout(0.2) (x)\n",
        "x = tfl.Dense(1,activation='sigmoid') (x)\n",
        "\n",
        "#models.Model   not models.Sequential\n",
        "model = tf.keras.models.Model(pre_trained_model.input, x)\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(optimizer = RMSprop(lr = 1e-4),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['acc']\n",
        "              )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weGzgyqEhm3I",
        "colab_type": "text"
      },
      "source": [
        "Applying model to cats vs dogs datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSq1JrMzhtUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFSbtPC-h4QT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary',\n",
        "    target_size = (150,150)\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary',\n",
        "    target_size = (150,150)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y_N4ZvcmC6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now we use our transfer learning model\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 20,\n",
        "    validation_steps = 50,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPqZfYIzmyD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.title('train and validation acc')\n",
        "plt.plot(epochs, acc, 'r', label = 'Train_acc')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Val_acc')\n",
        "plt.legend()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVsb3mMrLDR",
        "colab_type": "text"
      },
      "source": [
        "#Multiclass Classifications\n",
        "Rock paper scissors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfaSolV32tTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \\\n",
        "    -O /tmp/rps.zip\n",
        "  \n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip \\\n",
        "    -O /tmp/rps-test-set.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x24QDdQ82-_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "\n",
        "local_zip = '/tmp/rps-test-set.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzhJI2S14dhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = \"/tmp/rps\"\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "validation_dir = '/tmp/rps-test-set'\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150,150),\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "import tensorflow.keras.layers as tfl\n",
        "model = tf.keras.models.Sequential([\n",
        "    tfl.Conv2D(64, (3,3), activation = 'relu',\n",
        "               input_shape = (150, 150, 3)),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.Conv2D(64, (3,3), activation='relu'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.Conv2D(128, (3,3), activation= 'relu'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.Conv2D(128, (3,3), activation= 'relu'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.Flatten(),\n",
        "    tfl.Dense(512, activation= 'relu'),\n",
        "    tfl.Dropout(0.5),\n",
        "    tfl.Dense(3, activation='softmax')\n",
        "])\n",
        "model.summary()  \n",
        "model.compile (\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'rmsprop',  #no call function, direct \n",
        "    metrics = ['acc']\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K2x1BgA_6Wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs = 25,\n",
        "    validation_data = validation_generator,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHnIJXdaAZ1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='acc')\n",
        "plt.plot(epochs, val_acc, 'b', label ='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BICYc0KSQEyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload() \n",
        "\n",
        "for i in uploaded.keys():\n",
        "  path = i\n",
        "  img = image.load_img(path,\n",
        "                       target_size = (150,150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size = 10)\n",
        "  print(i)\n",
        "  print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}